---
tags:
  - DataScience
---

Bi-directional attention, a characteristic of [[Encoder Models|encoder models]], is the result of applying [[Self-attention|self-attention]] in both forward and backward directions, enabling each word to be influenced by all other words in the sentence.
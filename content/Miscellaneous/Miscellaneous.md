- [Obsidian Site Inspirations](#Obsidian%20Site%20Inspirations)
- [Books to read](#Books%20to%20read)
- [Blogs & Papers to read](#Blogs%20&%20Papers%20to%20read)
- [Potential courses](#Potential%20courses)
- [Talks to listen](#Talks%20to%20listen)
- [Interview Preparation](#Interview%20Preparation)
- [Tools to try](#Tools%20to%20try)
- [Techniques/Topics/Terms to learn](#Techniques/Topics/Terms%20to%20learn)
---

![[Semiotic Management Systems.png]]
Source: https://www.gapingvoid.com/semiotic-management-systems/

# Books to read
- [ ] [Situational Awareness: The Decade Ahead](https://www.forourposterity.com/situational-awareness-the-decade-ahead/) - #InProgress 
- [ ] The Psychology of Money
- [ ] [The Checklist Manifesto: How to Get Things Right](https://www.goodreads.com/book/show/6667514-the-checklist-manifesto?from_search=true&from_srp=true&qid=UDkR6CkEjo&rank=1)

# Blogs & Papers to read
- [x] [talk by @ilyasutat the Neural Information Processing Systems (December 10 - 15, 2024, Vancouver)](https://x.com/johnrushx/status/1867735273230282936?s=19)
- [ ] [[Build a LLM from Scratch]]
	- [ ] https://github.com/JohnMachado11/Build-a-Large-Language-Model-from-Scratch
	- [ ] [[A Vaswani - Attention Is All You Need - 2017]]
- [ ] https://karpathy.ai/zero-to-hero.html
- [ ] https://github.com/peggy1502/Amazing-Resources
- [ ] https://github.com/Shubhamsaboo/awesome-llm-apps/blob/main/ai_agent_tutorials/ai_medical_imaging_agent/ai_medical_imaging.py
- [ ] Multimodal AI agents - Gemini 2.0 | Project Astra | Project Mariner (deepmind.google/gemini)
- [ ] (https://www.linkedin.com/posts/armand-ruiz_this-project-got-more-than-11000-stars-on-activity-7273668186598785024-f0ji/?utm_source=share&utm_medium=member_android)
- [ ] [LinkedIn Post by Prof on AI agents, and couple of other related stuff](https://www.linkedin.com/posts/zhou-jo-yu-95327378_this-is-the-time-of-year-when-my-inboxes-activity-7273367390971641857-Ex3O?utm_source=share&utm_medium=member_desktop)
- [ ] [# Leopold Aschenbrenner's "Situational Awareness": AI from now to 2034](https://www.axios.com/2024/06/23/leopold-aschenbrenner-ai-future-silicon-valley)
- [ ] [Against Netflix](https://www.forourposterity.com/against-netflix/)
- [ ] https://www.jasonwei.net/thoughts
- [ ] https://bounded-regret.ghost.io/ai-forecasting-one-year-in/
- [ ] [Scaling laws for Neural Language Models](https://arxiv.org/pdf/2001.08361)
- [ ] [AI Forecasting - 1 year in](https://bounded-regret.ghost.io/ai-forecasting-one-year-in/)
- [ ] [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf)
- [ ] [GLaM: Efficient Scaling of Language Models with Mixture-of-Experts](https://arxiv.org/pdf/2112.06905)
- [ ] [Introducing Meta Llama 3: The most capable openly available LLM to date](https://ai.meta.com/blog/meta-llama-3/)
- [ ] [# Mozilla Report: How Common Crawl’s Data Infrastructure Shaped the Battle Royale over Generative AI](https://foundation.mozilla.org/en/blog/Mozilla-Report-How-Common-Crawl-Data-Infrastructure-Shaped-the-Battle-Royale-over-Generative-AI/)
- [ ] [Anthropic Computer Use Demo](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo) - Additional links [Computer use](https://docs.anthropic.com/en/docs/build-with-claude/computer-use)
- [ ] [Reinforcement Learning for Language Models](https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81)
- [ ] [# Measuring the impact of post-training enhancements](https://metr.github.io/autonomy-evals-guide/elicitation-gap/)
- [ ] [GPT-4o System Card](https://arxiv.org/pdf/2410.21276v1)
- [ ] [Will we run out of data? Limits of LLM scaling based on human-generated data](https://arxiv.org/pdf/2211.04325)
- [ ] [An Opinionated Guide to ML Research](http://joschu.net/blog/opinionated-guide-ml-research.html)
- [ ] [# Advancing medical AI with Med-Gemin](https://research.google/blog/advancing-medical-ai-with-med-gemini/)
- [ ] [Biocene thoughts](https://shelbyann.substack.com/)
- [ ] [Now Playing: Continuous low-power music recognition](https://arxiv.org/abs/1711.10958) - Arxiv
	- [ ] https://research.google/blog/googles-next-generation-music-recognition/
- [ ] [Introducing Chat. PT](https://openai.com/index/chatgpt/)
- [ ] [Introducing Structured Outputs in the API](https://openai.com/index/introducing-structured-outputs-in-the-api/)
- [ ] [OpenAI JSON Mode vs. Function Calling for Data Extraction](https://docs.llamaindex.ai/en/stable/examples/llm/openai_json_vs_function_calling/)
- [ ] [Open AI function calling tutorial](https://www.datacamp.com/tutorial/open-ai-function-calling-tutorial)
- [ ] [Learning to Reason with LLMs](https://openai.com/index/learning-to-reason-with-llms/)
- [ ] [OpenAI and others seek new path to smarter AI as current methods hit limitations](https://www.reuters.com/technology/artificial-intelligence/openai-rivals-seek-new-path-smarter-ai-current-methods-hit-limitations-2024-11-11/) - From Reuters
- [ ] [Transformer models: an introduction and catalog](https://arxiv.org/html/2302.07730v4)
- [ ] [# Transformer Architecture in Large Language Models](https://www.truefoundry.com/blog/transformer-architecture)
- [ ] [# Fine-Tuning BioBERT v1.1 on a Large Dataset: Classifying Medical Queries](https://medium.com/@fhirfly/fine-tuning-biobert-v1-1-on-a-large-dataset-classifying-medical-queries-c33b4d08ec6a)
- [ ] [# Google's new AI tool is a game-changer for students — here's how it works](https://www.tomsguide.com/ai/googles-new-ai-tool-is-a-game-changer-for-students-heres-how-it-works?utm_source=www.aikatana.com&utm_medium=newsletter&utm_campaign=nvidia-stunned-the-world-with-a-chatgpt-rival-that-s-as-good-as-gpt-4o&_bhlid=6eb21dd7d3e0550606ca2d4dc7cd7c240f82c1f8)
- [ ] [Large Language Model (LLM) Evaluation Metrics – BLEU and ROUGE](https://mlexplained.blog/2023/07/08/large-language-model-llm-evaluation-metrics-bleu-and-rouge/)
- [ ] [https://www.knime.com/blog/data-science-glossary](https://www.knime.com/blog/data-science-glossary)
- [ ] [Developers with AI assistants need to follow the pair programming model](https://stackoverflow.blog/2024/04/03/developers-with-ai-assistants-need-to-follow-the-pair-programming-model/?mkt_tok=NzE5LUVNSC01NjYAAAGShquC-HhsJPnnn1LgfI8FyQ3zj8M7OSAnEoMUaIzTayO0K4Mhx2dASZrCbdIzPj4xf0hTrv53GJckxevCusC_udkZPMPAup_Wl9ETUDiOR8xSTW70UCK_pDw&utm_campaign=teams-newsletter&utm_content=april-newsletter&utm_medium=email&utm_source=marketo)
- [ ] [Stack Overflow and OpenAI Partner to Strengthen the World’s Most Popular Large Language Models](https://stackoverflow.co/company/press/archive/openai-partnership)
- [ ] [Generative AI is coming for healthcare, and not everyone’s thrilled](https://techcrunch.com/2024/04/14/generative-ai-is-coming-for-healthcare-and-not-everyones-thrilled/?utm_campaign=tc_week_in_review&utm_medium=newsletter&_hsenc=p2ANqtz-9uj9q9pDoLscRLycmFwtp27j84gJtMp-abjFeN29oKsohZzNMGlYS5cjfiJFBQmWuhQS00cIqZLdAg6oyzSOsGvaaHTGe-P2RAgeHNCfGW72Y8n0s&_hsmi=303479898&utm_source=tc)
- [ ] https://www.linkedin.com/posts/gisenberg_someone-will-make-10m-in-2025-just-by-rebuilding-activity-7274777913143525376-4etF?utm_source=share&utm_medium=member_desktop

# Potential courses
*Note: Don't have to take all of them*

- [ ] [[DeepLearning.AI - Functions, Tools and Agents with LangChain]] - #InProgress 
- [ ] [Udemy course - Generative AI - GPT function calling, whisper, and langchain](https://www.udemy.com/course/generativeai-gpt-function-calling-whisper-langchain/?kw=function+calling&src=sac&couponCode=LETSLEARNNOW)
- [ ] [AI Agents in LangGraph](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/)
- [ ] [Encode Club - AI Bootcamp Q2 2024](https://encodeclub.notion.site/AI-Bootcamp-Q2-2024-2ff2d3d04af8445a926d14843a3d5198)

# Talks to listen
- [ ] [Stanford - Past Talks](https://stanford-medai.github.io/previous-talks/)
	- [ ] [MedAI #130: Me-LLaMA: Medical Foundation LLMs for Text Analysis and Beyond | Qianqian Xie](https://www.youtube.com/watch?v=V5FZBQMGSog)
- [ ] [Hugging Face Course Workshops: Question Answering](https://www.youtube.com/watch?v=Ihgk8kGLpIE)
- [ ] Dwarkesh podcast
	- [ ] [Dario Amodei (Anthropic CEO) - Scaling, Alignment, & AI Progress](https://www.dwarkeshpatel.com/p/dario-amodei?open=false#%C2%A7transcript) - 
	- [ ] [Will scaling work?](https://www.dwarkeshpatel.com/p/will-scaling-work)

# Tools to try
- [ ] [Introduction to NotebookLM](https://notebooklm.google.com/) by Google

# Techniques/Topics/Terms to learn
- [ ] `await`, `async`, `asyncio` - #InProgress 
- [ ] [[Decorators]] - #InProgress
- [ ] MMLU (Massive Multitask Language Understanding)
- [ ] Pre-training vs.  In context learning
- [ ] What is a post-training improvement?
- [ ] Test time compute overhang
- [ ] Model compression techniques like Pruning, quantization, distillation
- [x] [[FLOPS]] - second <- Train/test time compute are measured using this unit

# Notes strategy
- [ ] Effective way to take notes and condense them ([recommendations from ChatGPT](https://chatgpt.com/share/676e4333-aaf8-8013-bd5e-fda0950b52dc))

# Delete asap
## Startup structure
Knowledge/
└── Startups/
    ├── _index.md                     # Overview & navigation
    ├── Ecosystem/
    │   ├── Incubators/
    │   │   ├── YCombinator.md
    │   │   └── TechStars.md
    │   ├── Accelerators/
    │   ├── VCs/
    │   │   ├── a16z.md
    │   │   └── Sequoia.md
    │   └── Angel-Investors/
    ├── Companies/
    │   ├── Early-Stage/
    │   ├── Growth/
    │   └── Unicorns/
    ├── Resources/
    │   ├── Fundraising/
    │   ├── Pitch-Decks/
    │   └── Business-Models/
    └── Topics/
        ├── Valuations/
        ├── Market-Analysis/
        └── Exit-Strategies/